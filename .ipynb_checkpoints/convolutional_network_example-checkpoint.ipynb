{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some deep learning on images using famous convolution architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reference https://github.com/aymericdamien/TensorFlow-Examples\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10\n",
    "NUM_CLASSES = 10\n",
    "X_DIM = 28\n",
    "Y_DIM = 28\n",
    "PIXELS_PER_SAMPLE = X_DIM*Y_DIM\n",
    "logs_path = '/tmp/mnist_logs/example'\n",
    "import numpy as np\n",
    "unique_label = np.unique(np.argmax(mnist.train.labels, 1))\n",
    "print(unique_label)\n",
    "assert NUM_CLASSES == len(unique_label), 'number of label does not match'\n",
    "assert X_DIM*Y_DIM == mnist.train.images[0].size, 'total pixel does not match'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inference(X, dropout_prob):\n",
    "    '''\n",
    "    This function build model\n",
    "    :param:X: place hoder for input data\n",
    "    :return:prediction based on model\n",
    "    :rtype: tensor\n",
    "    '''\n",
    "    X=tf.reshape(X, shape=[-1, X_DIM, Y_DIM, 1])\n",
    "    # first convolution layer\n",
    "    with tf.name_scope(\"conv1\"):\n",
    "        W=tf.Variable(tf.random_normal([5, 5, 1, 8] ,stddev=.1), name='weight')\n",
    "        b = tf.Variable(tf.random_normal([8], stddev=.1), name= 'bias')\n",
    "        conv1 = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        conv1 = conv1+b\n",
    "        conv1 = tf.nn.relu(conv1) \n",
    "    max1= tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')     \n",
    "\n",
    "    with tf.name_scope(\"conv2\"):\n",
    "        W=tf.Variable(tf.random_normal([5, 5, 8, 16], stddev=.1), name='weight')\n",
    "        b = tf.Variable(tf.random_normal([16], stddev=.1), name= 'bias')\n",
    "        conv2 = tf.nn.conv2d(max1, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        conv2 = conv2+b\n",
    "        conv2 = tf.nn.relu(conv2)                      \n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    max2= tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') \n",
    "    # building fully connected layer. Need ot reshape output to [Batch, d2, d3, feature_maps] to\n",
    "    # [Batch, d2*d3*feature_maps]\n",
    "    # let figure out the shape\n",
    "    dim = 1\n",
    "    for dim_size in max2.get_shape().as_list()[1:]:\n",
    "        dim=dim*dim_size\n",
    "    print(max2.get_shape().as_list()[1:])    \n",
    "    print(dim)\n",
    "        \n",
    "    max2 = tf.reshape(max2, shape =[-1, dim])    \n",
    "    with tf.name_scope(\"fc\"):\n",
    "        W = tf.Variable(tf.random_normal([dim, 64], stddev=.1), name='weight')\n",
    "        b = tf.Variable(tf.random_normal([64], stddev=.1), name='bias')\n",
    "        fc1 = tf.matmul(max2, W) + b\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "       \n",
    "    fc1 = tf.nn.dropout(fc1, dropout_prob)\n",
    "    with tf.name_scope(\"output_layer\"):\n",
    "        W = tf.Variable(tf.random_normal([64, NUM_CLASSES],stddev=.1), name='weight')\n",
    "        b = tf.Variable(tf.random_normal([NUM_CLASSES], stddev=.1), name='bias')\n",
    "        fc2 = tf.matmul(fc1, W) + b\n",
    "    return fc2\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X =  tf.placeholder(tf.float32, [None, PIXELS_PER_SAMPLE])\n",
    "Y = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "# building model\n",
    "pred = inference(X, keep_prob)\n",
    "# Define loss and optimizer\n",
    "with tf.name_scope('Loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, Y))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=.5).minimize(loss)\n",
    "\n",
    "# Evaluate model\n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.scalar_summary(\"loss\", loss)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.scalar_summary(\"accuracy\", accuracy)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.merge_all_summaries()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    total_batch = int(mnist.train.num_examples/BATCH_SIZE)\n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.train.SummaryWriter(logs_path, graph=tf.get_default_graph())    \n",
    "    for eidx in range(NUM_EPOCHS):\n",
    "        for bidx in range(mnist.train.num_examples// BATCH_SIZE):\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            xs = xs.astype(np.float32)\n",
    "            ys= ys.astype(np.float32)\n",
    "            #p = np.float32(.5)\n",
    "            _, loss_val, summary_val= sess.run([ opt, loss ,merged_summary_op], feed_dict={X:xs, Y:ys, keep_prob:.5 })\n",
    "            # Write logs at every iteration\n",
    "            summary_writer.add_summary(summary_val, eidx * total_batch + bidx)\n",
    "            if (bidx+1)%100 == 0: # print result every 100 batch\n",
    "                accuracy_val = accuracy.eval(session=sess, feed_dict={X:xs, Y:ys, keep_prob:1.0})\n",
    "                print('epoch {} batch {} loss {} accu {}'.format(eidx +1 , bidx +1, loss_val, accuracy_val))\n",
    "        print('epoch {} # test accuracy {}#'.format(eidx +1, accuracy.eval(session=sess,\n",
    "            feed_dict= {X:mnist.test.images.astype(np.float32), Y: mnist.test.labels, keep_prob:1.0})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
