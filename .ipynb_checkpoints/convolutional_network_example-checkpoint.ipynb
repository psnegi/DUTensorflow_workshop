{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some deep learning on images using famous convolution architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 10\n",
    "NUM_CLASSES = 10\n",
    "X_DIM = 28\n",
    "Y_DIM = 28\n",
    "PIXELS_PER_SAMPLE = X_DIM*Y_DIM\n",
    "import numpy as np\n",
    "unique_label = np.unique(np.argmax(mnist.train.labels, 1))\n",
    "print(unique_label)\n",
    "assert NUM_CLASSES == len(unique_label), 'number of label does not match'\n",
    "assert X_DIM*Y_DIM == mnist.train.images[0].size, 'total pixel does not match'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inference(X, dropout_prob):\n",
    "    '''\n",
    "    This function build model\n",
    "    :param:X: place hoder for input data\n",
    "    :return:prediction based on model\n",
    "    :rtype: tensor\n",
    "    '''\n",
    "    X=tf.reshape(X, shape=[-1, X_DIM, Y_DIM, 1])\n",
    "    # first convolution layer\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        W=tf.Variable(tf.random_normal([5, 5, 1, 8]), name='weight')\n",
    "        b = tf.Variable(tf.random_normal([8]), name= 'bias')\n",
    "        conv1 = tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        conv1 = conv1+b\n",
    "        conv1 = tf.nn.relu(conv1) \n",
    "    max1= tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')     \n",
    "\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        W=tf.Variable(tf.random_normal([5, 5, 8, 16]), name='weight')\n",
    "        b = tf.Variable(tf.random_normal([16]), name= 'bias')\n",
    "        conv2 = tf.nn.conv2d(max1, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        conv2 = conv2+b\n",
    "        conv2 = tf.nn.relu(conv2)                      \n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    max2= tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') \n",
    "    # building fully connected layer. Need ot reshape output to [Batch, d2, d3, feature_maps] to\n",
    "    # [Batch, d2*d3*feature_maps]\n",
    "    # let figure out the shape\n",
    "    dim = 1\n",
    "    for dim_size in max2.get_shape().as_list()[1:]:\n",
    "        dim=dim*dim_size\n",
    "    print(max2.get_shape().as_list()[1:])    \n",
    "    print(dim)\n",
    "        \n",
    "    max2 = tf.reshape(max2, shape =[-1, dim])    \n",
    "    with tf.variable_scope(\"fc\"):\n",
    "        W = tf.Variable(tf.random_normal([dim, 64]), name='weight')\n",
    "        b = tf.Variable(tf.random_normal([64]), name='bias')\n",
    "        fc1 = tf.matmul(max2, W) + b\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "       \n",
    "    fc1 = tf.nn.dropout(fc1, dropout_prob)\n",
    "    with tf.variable_scope(\"output_layer\"):\n",
    "        W = tf.Variable(tf.random_normal([64, NUM_CLASSES]), name='weight')\n",
    "        b = tf.Variable(tf.random_normal([NUM_CLASSES]), name='bias')\n",
    "        fc2 = tf.matmul(fc1, W) + b\n",
    "    return fc2\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 64]\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "X =  tf.placeholder(tf.float32, [None, PIXELS_PER_SAMPLE])\n",
    "Y = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "# building model\n",
    "pred = inference(X, keep_prob)\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, Y))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=.1).minimize(loss)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for eidx in range(NUM_EPOCHS):\n",
    "        for bidx in range(mnist.train.num_examples// BATCH_SIZE):\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            xs = xs.astype(np.float32)\n",
    "            ys= ys.astype(np.float32)\n",
    "            _, loss_val= sess.run([opt, loss], feed_dict={X:xs, Y:ys, keep_prob:.5 })\n",
    "            if (bidx+1)%100 == 0: # print result every 100 batch\n",
    "                accuracy_val = accuracy.eval(session=sess, feed_dict={X:xs, Y:ys, keep_prob:1.0})\n",
    "                print('epoch {} batch {} loss {} accu {}'.format(eidx +1 , bidx +1, loss_val, accuracy_val))\n",
    "        print('epoch {} # test accuracy {}#'.format(eidx +1, accuracy.eval(session=sess,\n",
    "            feed_dict= {X:mnist.test.images.astype(np.float32), Y: mnist.test.labels, keep_prob:1.0})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
